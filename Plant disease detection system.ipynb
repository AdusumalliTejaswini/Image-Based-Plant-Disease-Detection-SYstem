{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOGCQ9ei+b3KNPU18MRBJOQ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":356},"id":"J7MQ8EUdb2qh","executionInfo":{"status":"error","timestamp":1716015064122,"user_tz":-330,"elapsed":485,"user":{"displayName":"Tejaswini Adusumalli","userId":"07070103084205212289"}},"outputId":"e22b7d88-bc8f-4833-ac61-7cf8fcd87ae9"},"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: 'C:\\\\Users\\\\Tejaswini Adusumalli\\\\Downloads\\\\archive (1)\\\\Train'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-5-aefb50714f36>\u001b[0m in \u001b[0;36m<cell line: 21>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;31m# Load the dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImageFolder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mr\"C:\\Users\\Tejaswini Adusumalli\\Downloads\\archive (1)\\Train\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;31m# Split the dataset into train, validation, and test sets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, transform, target_transform, loader, is_valid_file)\u001b[0m\n\u001b[1;32m    307\u001b[0m         \u001b[0mis_valid_file\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mCallable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m     ):\n\u001b[0;32m--> 309\u001b[0;31m         super().__init__(\n\u001b[0m\u001b[1;32m    310\u001b[0m             \u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m             \u001b[0mloader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, loader, extensions, transform, target_transform, is_valid_file)\u001b[0m\n\u001b[1;32m    142\u001b[0m     ) -> None:\n\u001b[1;32m    143\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_transform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtarget_transform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m         \u001b[0mclasses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_to_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m         \u001b[0msamples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_to_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextensions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_valid_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36mfind_classes\u001b[0;34m(self, directory)\u001b[0m\n\u001b[1;32m    216\u001b[0m             \u001b[0;34m(\u001b[0m\u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m \u001b[0mof\u001b[0m \u001b[0mall\u001b[0m \u001b[0mclasses\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mdictionary\u001b[0m \u001b[0mmapping\u001b[0m \u001b[0meach\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mto\u001b[0m \u001b[0man\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m         \"\"\"\n\u001b[0;32m--> 218\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfind_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36mfind_classes\u001b[0;34m(directory)\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0mSee\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;32mclass\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mDatasetFolder\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdetails\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \"\"\"\n\u001b[0;32m---> 40\u001b[0;31m     \u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mentry\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscandir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mentry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Couldn't find any class folder in {directory}.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:\\\\Users\\\\Tejaswini Adusumalli\\\\Downloads\\\\archive (1)\\\\Train'"]}],"source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import torch\n","from torchvision import datasets, transforms, models\n","from torch.utils.data.sampler import SubsetRandomSampler\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from datetime import datetime\n","from torchsummary import summary\n","from torch.utils.data import DataLoader\n","\n","# Define transformation for the dataset\n","transform = transforms.Compose([\n","    transforms.Resize(255),\n","    transforms.CenterCrop(224),\n","    transforms.ToTensor()\n","])\n","\n","# Load the dataset\n","dataset = datasets.ImageFolder(root=r\"C:\\Users\\Tejaswini Adusumalli\\Downloads\\archive (1)\\Train\", transform=transform)\n","\n","# Split the dataset into train, validation, and test sets\n","indices = list(range(len(dataset)))\n","split = int(np.floor(0.85 * len(dataset)))\n","validation = int(np.floor(0.70 * split))\n","\n","train_indices, validation_indices, test_indices = (\n","    indices[:validation],\n","    indices[validation:split],\n","    indices[split:]\n",")\n","\n","# Define data samplers and loaders\n","train_sampler = SubsetRandomSampler(train_indices)\n","validation_sampler = SubsetRandomSampler(validation_indices)\n","test_sampler = SubsetRandomSampler(test_indices)\n","\n","train_loader = DataLoader(dataset, batch_size=32, sampler=train_sampler)\n","validation_loader = DataLoader(dataset, batch_size=32, sampler=validation_sampler)\n","test_loader = DataLoader(dataset, batch_size=32, sampler=test_sampler)\n","\n","# Define the CNN model\n","class CNN(nn.Module):\n","    def _init_(self, K):\n","        super(CNN, self)._init_()\n","        self.conv_layers = nn.Sequential(\n","            nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=1),\n","            nn.ReLU(),\n","            nn.BatchNorm2d(32),\n","            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3, padding=1),\n","            nn.ReLU(),\n","            nn.BatchNorm2d(32),\n","            nn.MaxPool2d(2),\n","            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1),\n","            nn.ReLU(),\n","            nn.BatchNorm2d(64),\n","            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, padding=1),\n","            nn.ReLU(),\n","            nn.BatchNorm2d(64),\n","            nn.MaxPool2d(2),\n","            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1),\n","            nn.ReLU(),\n","            nn.BatchNorm2d(128),\n","            nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=1),\n","            nn.ReLU(),\n","            nn.BatchNorm2d(128),\n","            nn.MaxPool2d(2),\n","            nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, padding=1),\n","            nn.ReLU(),\n","            nn.BatchNorm2d(256),\n","            nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, padding=1),\n","            nn.ReLU(),\n","            nn.BatchNorm2d(256),\n","            nn.MaxPool2d(2),\n","        )\n","\n","        self.dense_layers = nn.Sequential(\n","            nn.Dropout(0.4),\n","            nn.Linear(50176, 1024),\n","            nn.ReLU(),\n","            nn.Dropout(0.4),\n","            nn.Linear(1024, K),\n","        )\n","\n","    def forward(self, X):\n","        out = self.conv_layers(X)\n","        out = out.view(-1, 50176)\n","        out = self.dense_layers(out)\n","        return out\n","\n","# Instantiate the model\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","targets_size = 39\n","model = CNN(targets_size)\n","model.to(device)\n","\n","# Print model summary\n","summary(model, (3, 224, 224))\n","\n","# Define loss function and optimizer\n","criterion = nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n","\n","# Training the model\n","epochs = 10\n","print(epochs)\n","for epoch in range(epochs):\n","    model.train()\n","    train_loss = 0.0\n","    correct_train = 0\n","    total_train = 0\n","    for images, labels in train_loader:\n","        images, labels = images.to(device), labels.to(device)\n","        optimizer.zero_grad()\n","        outputs = model(images)\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","        train_loss += loss.item()\n","        _, predicted = torch.max(outputs.data, 1)\n","        total_train += labels.size(0)\n","        correct_train += (predicted == labels).sum().item()\n","\n","    # Validation\n","    model.eval()\n","    valid_loss = 0.0\n","    correct_valid = 0\n","    total_valid = 0\n","    with torch.no_grad():\n","        for images, labels in validation_loader:\n","            images, labels = images.to(device), labels.to(device)\n","            outputs = model(images)\n","            loss = criterion(outputs, labels)\n","            valid_loss += loss.item()\n","            _, predicted = torch.max(outputs.data, 1)\n","            total_valid += labels.size(0)\n","            correct_valid += (predicted == labels).sum().item()\n","\n","    print(f'Epoch [{epoch + 1}/{epochs}], '\n","          f'Train Loss: {train_loss / len(train_loader):.4f}, '\n","          f'Train Accuracy: {100 * correct_train / total_train:.2f}%, '\n","          f'Validation Loss: {valid_loss / len(validation_loader):.4f}, '\n","          f'Validation Accuracy: {100 * correct_valid / total_valid:.2f}%')\n","\n","# Testing the model\n","model.eval()\n","correct_test = 0\n","total_test = 0\n","with torch.no_grad():\n","    for images, labels in test_loader:\n","        images, labels = images.to(device), labels.to(device)\n","        outputs = model(images)\n","        _, predicted = torch.max(outputs.data, 1)\n","        total_test += labels.size(0)\n","        correct_test += (predicted == labels).sum().item()\n","\n","print(f'Test Accuracy: {100 * correct_test / total_test:.2f}%')"]}]}